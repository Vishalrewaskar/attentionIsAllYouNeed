{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92efe289",
   "metadata": {},
   "source": [
    "# PyTorch \n",
    "a library to build and train neural networks.\n",
    "\n",
    "It mainly gives you 3 superpowers:\n",
    "1. Tensors ‚Üí like NumPy arrays but for deep learning\n",
    "2. Autograd ‚Üí automatic gradient calculation (backprop)\n",
    "3. Neural Network tools ‚Üí layers, loss functions, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3295bd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create Tensor\n",
    "x = torch.tensor([1,2,3,4])  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "560b3f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D Tensor (Matrix)\n",
    "\n",
    "twoD = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "]) \n",
    "\n",
    "twoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoD.shape  # Means ‚Üí 4 rows, 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a3b41ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8513, 0.9815, 0.0967, 0.3665],\n",
       "        [0.6521, 0.0226, 0.1485, 0.0740],\n",
       "        [0.1896, 0.1137, 0.8555, 0.6984]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensors (Used in Neural Networks)\n",
    "\n",
    "R = torch.rand(3,4)   # Creates a 3√ó4 tensor with random numbers between 0 and 1.\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0849b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "==================================================\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Zeros and Ones\n",
    "\n",
    "zeros = torch.zeros(2,3)\n",
    "ones = torch.ones(2,3)\n",
    "\n",
    "print(zeros)\n",
    "print(50*\"=\")\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4ee6c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "==================================================\n",
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "# Tensor Math (Like NumPy)\n",
    "# element-wise addition, multiplication\n",
    "\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5,6])\n",
    "\n",
    "print(a+b)\n",
    "print(50*\"=\")\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdeebd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([1, 2, 3]) device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU (Makes Deep Learning Fast)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# If True, you can move tensor to GPU:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.tensor([1, 2, 3]).to(device)\n",
    "print(x,\"device: \",device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddb6be",
   "metadata": {},
   "source": [
    "# üéØ Assignment 1\n",
    "Write code that:\n",
    "1. Creates a random tensor of shape (5, 3)\n",
    "2. Prints:\n",
    "    - The tensor\n",
    "    - Its shape\n",
    "3. Creates another random tensor of same shape\n",
    "4. Adds them\n",
    "5. Moves result to GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5927, 0.9789, 0.5670],\n",
      "        [0.9655, 0.9555, 0.8922],\n",
      "        [0.6773, 0.6253, 0.9931],\n",
      "        [0.3056, 0.8041, 0.1652],\n",
      "        [0.2000, 0.9185, 0.6720]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = torch.rand(5,3)\n",
    "print(r1)\n",
    "r1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1315515b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1168, 0.2076, 0.0989],\n",
       "        [0.1573, 0.2221, 0.6020],\n",
       "        [0.4740, 0.7334, 0.2192],\n",
       "        [0.9572, 0.0553, 0.9345],\n",
       "        [0.1558, 0.8586, 0.7008]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = torch.rand(5,3)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a66e324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7095, 1.1866, 0.6659],\n",
       "        [1.1228, 1.1776, 1.4942],\n",
       "        [1.1513, 1.3586, 1.2122],\n",
       "        [1.2628, 0.8594, 1.0996],\n",
       "        [0.3557, 1.7771, 1.3728]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1+r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6068284",
   "metadata": {},
   "source": [
    "# üß© LESSON 2 ‚Äî AUTOGRAD (How Neural Networks Learn)\n",
    "Neural networks learn by adjusting weights using gradients.\n",
    "\n",
    "Normally, you'd have to manually calculate derivatives like:\n",
    "- ùë¶ = ùë•^2 + 2ùë• + 1            \n",
    "- ùëëùë¶/dx = 2ùë• + 2\n",
    "\n",
    "But PyTorch says:\n",
    "‚ÄúRelax. I got this.‚Äù\n",
    "\n",
    "That system = Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42800236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor That Tracks Gradients\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff708742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a Function\n",
    "y = x**2 + 2*x + 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "896d9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "y.backward()    # PyTorch, compute dy/dx‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f9fa826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "# Get the Gradient\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626eacb",
   "metadata": {},
   "source": [
    "# üéØ Assignment 2\n",
    "Write code that:\n",
    "1. Creates a tensor x = 3.0 with gradient tracking\n",
    "2. Define:\n",
    "- ùë¶ = 4ùë•^2 + 3ùë•\n",
    "3. Call .backward()\n",
    "4. Print gradient\n",
    "\n",
    "Then verify manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15d3f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# function\n",
    "y = 4*x**2+3*x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0d943be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1219c7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616dafc7",
   "metadata": {},
   "source": [
    "# üß© LESSON 3 ‚Äî Your First Neural Network\n",
    "We will make a model that learns this line:\n",
    "- ùë¶ = 2ùë• + 1\n",
    "\n",
    "If the model learns correctly ‚Üí it discovers slope = 2 and bias = 1 by itself.\n",
    "\n",
    "built : x ‚Üí Linear ‚Üí y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ff5470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn            # neural network tools \n",
    "import torch.optim as optim      # optimizers (how weights update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "022a7c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Model\n",
    "model = nn.Linear(1,1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "442592f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data\n",
    "x = torch.tensor([\n",
    "    [1.0], [2.0], [3.0],[4.0]\n",
    "])\n",
    "\n",
    "y = torch.tensor([\n",
    "    [3.0], [5.0], [7.0], [9.0]     # y = 2x + 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4204a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2bed47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d93a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 1.9916598796844482\n",
      "Bias: 1.0245212316513062\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight\", model.weight.item())\n",
    "print(\"Bias:\", model.bias.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b227f",
   "metadata": {},
   "source": [
    "# üß© LESSON 5 ‚Äî Multi-Layer Neural Network + Activation\n",
    "built : x ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3a4de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6520a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Non-Linear Dataset\n",
    "# We‚Äôll train the model om: y=x^2\n",
    "\n",
    "x = torch.linspace(-5, 5, 100).view(-1,1)\n",
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1753caa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6af99318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Multi-Layer Model\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 10),  # input ‚Üí hidden\n",
    "    nn.ReLU(),         # activation\n",
    "    nn.Linear(10, 1)   # hidden ‚Üí output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e8a198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & Optimizer\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09f5a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: <built-in method item of Tensor object at 0x0000016EBC9DF660>:.4f\n",
      "Epoch 200, Loss: <built-in method item of Tensor object at 0x0000016EBC9F5090>:.4f\n",
      "Epoch 400, Loss: <built-in method item of Tensor object at 0x0000016EBC9DF7F0>:.4f\n",
      "Epoch 600, Loss: <built-in method item of Tensor object at 0x0000016EBC9DF7F0>:.4f\n",
      "Epoch 800, Loss: <built-in method item of Tensor object at 0x0000016EBC9DF7F0>:.4f\n",
      "Epoch 1000, Loss: <built-in method item of Tensor object at 0x0000016EBC9DE260>:.4f\n",
      "Epoch 1200, Loss: <built-in method item of Tensor object at 0x0000016EBC9DE260>:.4f\n",
      "Epoch 1400, Loss: <built-in method item of Tensor object at 0x0000016EBC9DF1B0>:.4f\n",
      "Epoch 1600, Loss: <built-in method item of Tensor object at 0x0000016EBC9DF1B0>:.4f\n",
      "Epoch 1800, Loss: <built-in method item of Tensor object at 0x0000016EBC9DE260>:.4f\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "for epoch in range(2000):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 200 ==0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item}:.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fae1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4.259612083435059\n",
      "Actual: 4.0\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([[2.0]])\n",
    "print(\"Prediction:\", model(test).item())\n",
    "print(\"Actual:\", 2.0**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634d875",
   "metadata": {},
   "source": [
    "# üß© RNN (Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b03d5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45d26a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [2, 3, 4],\n",
    "    [3, 4, 5],\n",
    "    [4, 5, 6]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "targets = torch.tensor([[4], [5], [6], [7]], dtype=torch.float32)\n",
    "\n",
    "# reshape to (batch, seq_len, features)\n",
    "sequences = sequences.view(4, 3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afb9363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN Model\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=1, hidden_size=8, batch_first=True)\n",
    "        self.fc = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)          # RNN processes sequence\n",
    "        last_out = out[:, -1, :]      # take last time step\n",
    "        out = self.fc(last_out)       # map to output\n",
    "        return out\n",
    "\n",
    "model = SimpleRNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90375074",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed318ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 38.34813690185547\n",
      "50 3.676180362701416\n",
      "100 1.214820146560669\n",
      "150 1.1688661575317383\n",
      "200 0.2783965468406677\n",
      "250 0.06892208009958267\n",
      "300 0.03281386196613312\n",
      "350 0.012287240475416183\n",
      "400 0.0037926321383565664\n",
      "450 0.0009510623058304191\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    pred = model(sequences)\n",
    "    loss = loss_fn(pred, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(epoch, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26600ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.3169]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([[8, 9, 10]], dtype=torch.float32).view(1,3,1)\n",
    "print(model(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485374e",
   "metadata": {},
   "source": [
    "# üß© LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42bf0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "042791ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [2,3,4],\n",
    "    [3,4,5],\n",
    "    [4,5,6]\n",
    "], dtype=torch.float32).view(4,3,1)\n",
    "\n",
    "targets = torch.tensor([\n",
    "    [4],\n",
    "    [5],\n",
    "    [6],\n",
    "    [7]\n",
    "], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ecf5506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=16, batch_first=True)\n",
    "        self.fc = nn.Linear(16,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        last_output = out[:, -1, :]\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "model = SimpleLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d306597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7528700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 32.4640\n",
      "Epoch 50, Loss 1.3298\n",
      "Epoch 100, Loss 0.3852\n",
      "Epoch 150, Loss 0.0045\n",
      "Epoch 200, Loss 0.0000\n",
      "Epoch 250, Loss 0.0000\n",
      "Epoch 300, Loss 0.0000\n",
      "Epoch 350, Loss 0.0000\n",
      "Epoch 400, Loss 0.0000\n",
      "Epoch 450, Loss 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    pred = model(sequences)\n",
    "    loss = loss_fn(pred, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6386087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7.250628471374512\n",
      "Expected: 11\n"
     ]
    }
   ],
   "source": [
    "test_seq = torch.tensor([[8, 9, 10]], dtype=torch.float32).view(1,3,1)\n",
    "print(\"Prediction:\", model(test_seq).item())\n",
    "print(\"Expected:\", 11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163f915",
   "metadata": {},
   "source": [
    "# PyTorch Muscle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bd7fea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [3,4,5,6],\n",
    "    [5,6,7,8]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(\"shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a82b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cee8bc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:  tensor([[ 2.,  4.,  6.,  8.],\n",
      "        [ 6.,  8., 10., 12.],\n",
      "        [10., 12., 14., 16.]])\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "x = x* 2\n",
    "print(\"Tensor: \", x)\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c41eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient:  tensor(26.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "y = 3*x**2+2*x\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(\"Gradient: \", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "014f5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient:  tensor(30.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "y = 3*x**2\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(\"Gradient: \", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82cb9d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "LSTM: Expected input to be 2D or 3D, got 0D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m      3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[61], line 10\u001b[0m, in \u001b[0;36mSimpleLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 10\u001b[0m     out, (h_n, c_n) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[0;32m     11\u001b[0m     last_output \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(last_output)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1075\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m-> 1075\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1076\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1077\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m   1079\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 0D instead"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "812cac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model  = nn.Sequential(\n",
    "    nn.Linear(1, 8),\n",
    "    nn.ReLU(),\n",
    "    nn. Linear(8,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d14883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2236.39697265625\n",
      "1755.2322998046875\n",
      "1171.8070068359375\n",
      "782.3077392578125\n",
      "522.2747802734375\n",
      "348.6748046875\n",
      "232.77813720703125\n",
      "155.4046630859375\n",
      "103.74940490722656\n",
      "69.263916015625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ")\n",
    "\n",
    "# Data\n",
    "x = torch.tensor([[4.0]])\n",
    "y = torch.tensor([[48.0]])  # 3*x^2 = 48\n",
    "\n",
    "# Loss & Optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training\n",
    "for epoch in range(100):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0fb203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([16, 1])\n",
      "0.bias torch.Size([16])\n",
      "2.weight torch.Size([1, 16])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.grad.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5612fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(200,2)\n",
    "y = (X[:, 0] + X[:,1] >0 ).float().view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eec2e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9107d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "186bd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7048\n",
      "Epoch 20, Loss: 0.6829\n",
      "Epoch 40, Loss: 0.6622\n",
      "Epoch 60, Loss: 0.6425\n",
      "Epoch 80, Loss: 0.6234\n",
      "Epoch 100, Loss: 0.6048\n",
      "Epoch 120, Loss: 0.5868\n",
      "Epoch 140, Loss: 0.5691\n",
      "Epoch 160, Loss: 0.5519\n",
      "Epoch 180, Loss: 0.5351\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1b17c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "    predicted_classes = (pred > 0.5).float()\n",
    "    accuracy = (predicted_classes == y).float().mean()\n",
    "\n",
    "print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58934cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
