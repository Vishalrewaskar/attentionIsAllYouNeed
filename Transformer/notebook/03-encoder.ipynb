{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c035f3ad",
   "metadata": {},
   "source": [
    "# 1. Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58dde62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = \"The animal did not cross the street because it was tired.\"\n",
    "tokens = re.findall(r\"\\w+\", text.lower())\n",
    "\n",
    "sentences = [tokens]\n",
    "\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=64,\n",
    "    window=3,\n",
    "    min_count=1,\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "X = np.array([word2vec_model.wv[word] for word in tokens])  # (seq_len, d_model)\n",
    "\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    PE = np.zeros((seq_len, d_model))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            PE[pos, i] = np.sin(pos / (10000 ** (i/d_model)))\n",
    "            PE[pos, i+1] = np.cos(pos / (10000 ** (i/d_model)))\n",
    "    return PE\n",
    "\n",
    "X = X + positional_encoding(len(tokens), 64)\n",
    "\n",
    "d_model = 64\n",
    "num_heads = 8\n",
    "d_k = d_v = d_model // num_heads\n",
    "seq_len = X.shape[0]\n",
    "\n",
    "W_Q = np.random.randn(d_model, d_model) / np.sqrt(d_model)\n",
    "W_K = np.random.randn(d_model, d_model) / np.sqrt(d_model)\n",
    "W_V = np.random.randn(d_model, d_model) / np.sqrt(d_model)\n",
    "W_O = np.random.randn(d_model, d_model) / np.sqrt(d_model)\n",
    "\n",
    "Q = np.matmul(X, W_Q)\n",
    "K = np.matmul(X, W_K)\n",
    "V = np.matmul(X, W_V)\n",
    "\n",
    "Q = Q.reshape(seq_len, num_heads, d_k).transpose(1,0,2)\n",
    "K = K.reshape(seq_len, num_heads, d_k).transpose(1,0,2)\n",
    "V = V.reshape(seq_len, num_heads, d_v).transpose(1,0,2)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "\n",
    "# Attention per head\n",
    "\n",
    "heads = []\n",
    "attention_weights = []\n",
    "\n",
    "for h in range(num_heads):\n",
    "    scores = np.matmul(Q[h], np.transpose(K[h]))\n",
    "    scores = scores / np.sqrt(d_k)\n",
    "    weights = softmax(scores)\n",
    "    attention_weights.append(weights)\n",
    "    head = np.matmul(weights, V[h])\n",
    "    heads.append(head)\n",
    "\n",
    "attention_weights = np.array(attention_weights)\n",
    "\n",
    "concat = np.concatenate(heads, axis=-1)\n",
    "\n",
    "output = np.matmul(concat, W_O)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ab5e2",
   "metadata": {},
   "source": [
    "# 2. Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7f81246",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_1 = X + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f0ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x,   eps=1e-6):\n",
    "    mean = np.mean(x, axis=-1, keepdims = True)\n",
    "    std = np.std(x, axis=-1, keepdims=True)\n",
    "    return (x - mean) / (std + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83bdb246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.29273112e+00  1.30959137e-01 -1.08921281e+00  1.19285061e+00\n",
      "  -4.77243024e-01 -5.50448013e-01 -8.07827595e-01  1.17195286e+00\n",
      "   1.45766140e-01  4.85671665e-01 -4.95144367e-01  1.16525398e+00\n",
      "  -4.91917295e-01  7.91929382e-01 -8.80785357e-01  4.73727454e-01\n",
      "   9.44627997e-01 -3.04762188e-01 -3.98028893e-01  2.32567211e-02\n",
      "  -9.51372681e-01 -3.37252636e-01  4.08138218e-02  1.51006150e+00\n",
      "  -2.37335883e+00  5.51404488e-01 -7.39795400e-01  1.49929438e+00\n",
      "  -1.27731472e+00  3.11810120e-01 -6.72268788e-01  3.94887864e-01\n",
      "  -3.86202813e-01 -1.22388756e-01 -6.62562419e-01  1.28645625e+00\n",
      "  -2.19720733e-01  3.51242428e-01 -6.58905312e-01 -7.74640068e-02\n",
      "  -1.79063887e+00  1.34415203e+00 -1.77574501e+00  1.04404298e+00\n",
      "  -7.25967457e-02 -4.91043009e-01 -3.45125670e-01  9.54061556e-01\n",
      "   3.60521022e-01  1.30162417e+00  2.30100633e-02  9.35219661e-01\n",
      "   1.58880997e-02 -4.25080616e-01 -7.57058696e-01  1.97471654e+00\n",
      "  -1.20048220e+00  2.59132477e+00  7.16690051e-02 -4.72429103e-02\n",
      "  -1.67702350e+00  1.59556271e+00 -3.26936040e-02  1.97679202e-01]\n",
      " [-1.46378324e+00 -4.63692846e-01 -3.78701632e-01  8.75735752e-01\n",
      "   1.23515592e-01 -8.05769795e-01 -4.11904670e-01  1.04304905e+00\n",
      "   4.97909919e-01  3.94339259e-01 -3.20083321e-01  1.17249454e+00\n",
      "  -3.60576974e-01  7.47213623e-01 -8.02440979e-01  4.54120348e-01\n",
      "   1.05438434e+00 -3.85147229e-01 -3.49644320e-01 -7.45480631e-03\n",
      "  -1.00783118e+00 -4.36933529e-01  4.10527857e-02  1.53957619e+00\n",
      "  -2.53434801e+00  5.29324818e-01 -8.12825860e-01  1.53628698e+00\n",
      "  -1.36865926e+00  2.81308386e-01 -7.20116396e-01  3.75059564e-01\n",
      "  -4.68578208e-01 -1.72062754e-01 -7.23959780e-01  1.32342108e+00\n",
      "  -2.91689769e-01  3.58030327e-01 -7.47907604e-01 -1.27387892e-01\n",
      "  -1.90893874e+00  1.38294612e+00 -1.90431840e+00  1.05448740e+00\n",
      "  -1.22884591e-01 -5.70038170e-01 -3.86571038e-01  9.42889315e-01\n",
      "   3.27254503e-01  1.29151412e+00 -1.43515943e-02  9.20908681e-01\n",
      "  -2.56575978e-02 -5.12859040e-01 -8.64688190e-01  2.06866770e+00\n",
      "  -1.32863132e+00  2.71899873e+00  1.79680296e-02 -1.06735376e-01\n",
      "  -1.84578353e+00  1.60775067e+00 -8.29750657e-02  1.55724885e-01]\n",
      " [-1.35134242e+00 -1.61615039e+00  8.73349821e-03  5.50410190e-02\n",
      "   5.46670797e-01 -1.27584685e+00 -8.33951939e-04  7.53212128e-01\n",
      "   8.27391606e-01  2.37037389e-01 -2.44413972e-02  1.07211883e+00\n",
      "  -1.56775144e-01  6.59379986e-01 -6.47619635e-01  3.85189927e-01\n",
      "   1.19150775e+00 -3.71999813e-01 -2.58547447e-01 -3.54674429e-02\n",
      "  -9.26434698e-01 -4.32093132e-01  9.23389308e-02  1.56314029e+00\n",
      "  -2.47782027e+00  5.41487389e-01 -7.65776185e-01  1.52601058e+00\n",
      "  -1.31099158e+00  2.58175517e-01 -7.12342692e-01  3.77674670e-01\n",
      "  -4.45788059e-01 -1.84184497e-01 -7.12588348e-01  1.33810125e+00\n",
      "  -2.67296916e-01  3.40262810e-01 -7.13990763e-01 -1.43374697e-01\n",
      "  -1.87958011e+00  1.37977574e+00 -1.89056703e+00  1.08020407e+00\n",
      "  -9.38911695e-02 -5.67505253e-01 -3.99618792e-01  9.18275105e-01\n",
      "   3.60075596e-01  1.26756175e+00  1.31440478e-02  9.03123579e-01\n",
      "  -9.15416586e-03 -4.94669176e-01 -8.59676757e-01  2.04837159e+00\n",
      "  -1.31670436e+00  2.67392473e+00  4.02912040e-02 -7.85243107e-02\n",
      "  -1.79123205e+00  1.61444010e+00 -5.71330072e-02  1.97300653e-01]\n",
      " [-2.07892781e+00 -2.12056517e+00 -1.88863385e-01 -6.74177605e-01\n",
      "   6.85966067e-01 -1.77611413e+00  2.87888312e-01  3.32962093e-01\n",
      "   1.06679201e+00 -6.48763105e-03  2.16462526e-01  8.84987762e-01\n",
      "   1.00497718e-01  5.63690166e-01 -4.36418536e-01  3.75958488e-01\n",
      "   1.27002534e+00 -3.46397897e-01 -1.16802388e-01  3.21541054e-02\n",
      "  -7.69105669e-01 -3.48913133e-01  1.63027490e-01  1.50501193e+00\n",
      "  -2.28144632e+00  5.42011896e-01 -6.64502466e-01  1.50394279e+00\n",
      "  -1.20539687e+00  3.04414308e-01 -5.83437849e-01  3.83903978e-01\n",
      "  -3.89858603e-01 -1.57528939e-01 -6.19267089e-01  1.29641420e+00\n",
      "  -2.08589559e-01  3.46059061e-01 -6.25534942e-01 -8.50683898e-02\n",
      "  -1.75804354e+00  1.31680848e+00 -1.71361559e+00  1.05336470e+00\n",
      "  -4.70501282e-02 -4.95531450e-01 -3.02686368e-01  9.01417921e-01\n",
      "   3.94864435e-01  1.24687873e+00  4.21989687e-02  9.03934914e-01\n",
      "   1.87386806e-02 -4.25463926e-01 -7.67864572e-01  1.95930716e+00\n",
      "  -1.19954943e+00  2.57613915e+00  8.71422767e-02 -3.36496649e-02\n",
      "  -1.67182803e+00  1.53889420e+00 -1.23674739e-02  2.09194685e-01]\n",
      " [-2.90281948e+00 -1.60941737e+00 -8.16596196e-01 -9.83426169e-01\n",
      "   4.34251756e-01 -2.20488747e+00  3.55876163e-01 -6.84222998e-02\n",
      "   1.20110579e+00 -2.60150251e-01  4.25100536e-01  7.05300775e-01\n",
      "   3.01893014e-01  4.64758567e-01 -2.66881162e-01  3.30554503e-01\n",
      "   1.33993961e+00 -3.14742597e-01 -3.50081439e-02  4.28537038e-02\n",
      "  -6.24403132e-01 -3.18376452e-01  2.49664907e-01  1.44579906e+00\n",
      "  -2.08907136e+00  5.60788412e-01 -5.80877866e-01  1.45783063e+00\n",
      "  -1.10681524e+00  3.13497180e-01 -5.09499848e-01  4.08047486e-01\n",
      "  -3.14838705e-01 -9.11612092e-02 -5.38590970e-01  1.27413516e+00\n",
      "  -1.40694263e-01  3.63850673e-01 -5.64870043e-01 -2.99877089e-02\n",
      "  -1.61657994e+00  1.29103249e+00 -1.58574489e+00  1.05699359e+00\n",
      "  -2.33129519e-02 -4.38020497e-01 -2.22945607e-01  9.07243081e-01\n",
      "   4.14153412e-01  1.20314420e+00  9.94195952e-02  8.82517930e-01\n",
      "   7.50626910e-02 -3.56239163e-01 -6.81615765e-01  1.91678462e+00\n",
      "  -1.07163738e+00  2.47214035e+00  1.03690649e-01  1.18837436e-02\n",
      "  -1.52497932e+00  1.50212966e+00  4.56975212e-02  2.35471994e-01]\n",
      " [-3.04280615e+00 -5.87827148e-01 -1.53322314e+00 -7.60839199e-01\n",
      "  -4.84437225e-02 -2.48356819e+00  2.51587617e-01 -4.33812355e-01\n",
      "   1.22322120e+00 -5.60986027e-01  5.51005613e-01  4.92120317e-01\n",
      "   4.35882238e-01  3.75246686e-01 -1.39799221e-01  2.82039442e-01\n",
      "   1.44846714e+00 -3.29278460e-01  4.24461312e-02  3.21985204e-02\n",
      "  -5.40490082e-01 -3.18291097e-01  3.23189984e-01  1.41730474e+00\n",
      "  -1.97339170e+00  5.57329372e-01 -5.09581007e-01  1.44144369e+00\n",
      "  -1.05784792e+00  3.21235185e-01 -4.61931635e-01  4.19721208e-01\n",
      "  -2.48778598e-01 -7.72065231e-02 -5.16666677e-01  1.27349756e+00\n",
      "  -1.11307685e-01  3.81018233e-01 -5.54553760e-01 -2.41599156e-02\n",
      "  -1.58412397e+00  1.29133642e+00 -1.54993109e+00  1.03604633e+00\n",
      "   7.45689111e-03 -4.21310221e-01 -2.12743984e-01  9.22165040e-01\n",
      "   4.25082273e-01  1.23179809e+00  9.41908140e-02  9.16674961e-01\n",
      "   9.13321977e-02 -3.27642558e-01 -6.34076746e-01  1.88694778e+00\n",
      "  -1.01931963e+00  2.44837863e+00  1.36205231e-01  2.19083502e-02\n",
      "  -1.49601734e+00  1.50626978e+00  4.73580272e-02  2.27850058e-01]\n",
      " [-2.37632352e+00  1.03292493e-01 -1.98502784e+00 -1.23146885e-01\n",
      "  -6.49402108e-01 -2.55564452e+00 -6.21245554e-02 -7.76707584e-01\n",
      "   1.18801589e+00 -8.90917356e-01  6.16345527e-01  2.46267260e-01\n",
      "   5.44676364e-01  2.21919385e-01 -2.53643660e-02  2.18044472e-01\n",
      "   1.57628707e+00 -4.04421746e-01  9.88321723e-02  3.00670998e-02\n",
      "  -5.10382796e-01 -3.50598988e-01  3.73835510e-01  1.41920768e+00\n",
      "  -1.96880968e+00  5.79881036e-01 -4.78549903e-01  1.44287672e+00\n",
      "  -1.06159031e+00  3.36186895e-01 -4.34473908e-01  4.20335378e-01\n",
      "  -2.55698160e-01 -6.26276132e-02 -5.26824710e-01  1.28621379e+00\n",
      "  -1.33488972e-01  4.14954951e-01 -5.58141794e-01 -1.54539059e-02\n",
      "  -1.60478486e+00  1.31635033e+00 -1.55120350e+00  1.05190815e+00\n",
      "   4.24003394e-03 -4.40326702e-01 -2.01165713e-01  9.38084458e-01\n",
      "   4.01185151e-01  1.21920525e+00  1.15223019e-01  9.35340631e-01\n",
      "   8.65364637e-02 -3.15424596e-01 -6.73631466e-01  1.91056923e+00\n",
      "  -1.04584023e+00  2.52313162e+00  1.36288747e-01 -5.09906374e-03\n",
      "  -1.53974498e+00  1.53920441e+00  5.23203003e-02  2.36114823e-01]\n",
      " [-1.42946258e+00 -1.31566691e-01 -1.94312247e+00  6.48914190e-01\n",
      "  -1.18192066e+00 -2.35562412e+00 -5.06871951e-01 -1.00156200e+00\n",
      "   1.04123579e+00 -1.20767308e+00  6.56575498e-01  1.37470512e-03\n",
      "   6.29126153e-01  6.88944463e-02  6.92971384e-02  1.04835675e-01\n",
      "   1.69659157e+00 -4.74944599e-01  1.79206479e-01 -2.41791829e-02\n",
      "  -4.61232355e-01 -3.90127807e-01  4.09907409e-01  1.45584932e+00\n",
      "  -2.00202765e+00  5.69070912e-01 -4.82253421e-01  1.48028763e+00\n",
      "  -1.07179882e+00  3.40818238e-01 -4.58282755e-01  4.13784722e-01\n",
      "  -2.03627064e-01 -3.62758367e-02 -5.34382006e-01  1.31321416e+00\n",
      "  -1.31551337e-01  4.05166758e-01 -5.65576240e-01 -4.89809579e-03\n",
      "  -1.65268339e+00  1.35042344e+00 -1.59838966e+00  1.06346444e+00\n",
      "  -3.25281918e-02 -4.23531517e-01 -2.11711365e-01  9.53018816e-01\n",
      "   4.04536215e-01  1.26311193e+00  1.01628064e-01  9.87983347e-01\n",
      "   7.72672483e-02 -3.53722062e-01 -6.91394889e-01  1.97305479e+00\n",
      "  -1.05783875e+00  2.58178500e+00  1.63954404e-01 -2.76948429e-02\n",
      "  -1.57359401e+00  1.55935840e+00  1.58782502e-02  2.42434266e-01]\n",
      " [-1.05235927e+00 -1.11698406e+00 -1.29370990e+00  1.17911913e+00\n",
      "  -1.46263385e+00 -1.81847654e+00 -1.01344373e+00 -1.00179768e+00\n",
      "   8.28775803e-01 -1.45545571e+00  5.94327653e-01 -2.56844847e-01\n",
      "   7.06249914e-01 -1.07912891e-01  1.54330711e-01 -1.85453865e-02\n",
      "   1.77670913e+00 -5.40052097e-01  2.67528079e-01 -9.43642123e-02\n",
      "  -3.88412510e-01 -4.03135799e-01  4.79315778e-01  1.46605324e+00\n",
      "  -1.96319649e+00  6.02075473e-01 -4.50497142e-01  1.49617927e+00\n",
      "  -1.06026182e+00  3.53015162e-01 -4.45625550e-01  4.25095673e-01\n",
      "  -1.75099510e-01 -3.53026075e-02 -4.94553891e-01  1.32040147e+00\n",
      "  -1.37702931e-01  4.41542063e-01 -5.47656136e-01 -2.76672822e-02\n",
      "  -1.67376616e+00  1.37495616e+00 -1.62493372e+00  1.09103964e+00\n",
      "  -1.08745478e-02 -4.12040613e-01 -2.00432016e-01  9.80890366e-01\n",
      "   3.95033283e-01  1.29613275e+00  9.79359642e-02  1.00097773e+00\n",
      "   7.21433598e-02 -3.23765177e-01 -7.11702778e-01  1.98472508e+00\n",
      "  -1.06623542e+00  2.63138694e+00  1.67995486e-01 -2.19039382e-02\n",
      "  -1.60642244e+00  1.57401954e+00  1.82818667e-02  2.37531914e-01]\n",
      " [-1.66047627e+00 -1.88854592e+00 -4.41474221e-01  1.09538895e+00\n",
      "  -1.38745119e+00 -1.17263198e+00 -1.38225098e+00 -7.88693768e-01\n",
      "   5.45924052e-01 -1.56602660e+00  5.14656858e-01 -4.50289255e-01\n",
      "   7.19962866e-01 -3.18919699e-01  2.22667313e-01 -1.55350324e-01\n",
      "   1.85944196e+00 -6.02457426e-01  3.70180833e-01 -1.38008197e-01\n",
      "  -3.15648688e-01 -3.96338654e-01  5.29264544e-01  1.45539176e+00\n",
      "  -1.89988592e+00  5.82806580e-01 -4.00631537e-01  1.52095053e+00\n",
      "  -9.81575397e-01  3.69472400e-01 -4.16154076e-01  4.62655245e-01\n",
      "  -1.81867041e-01 -1.81641940e-02 -4.84129501e-01  1.29877268e+00\n",
      "  -8.16950386e-02  4.65840998e-01 -5.08063754e-01 -2.15281353e-02\n",
      "  -1.60639161e+00  1.39792364e+00 -1.57741174e+00  1.08406222e+00\n",
      "   2.10672031e-02 -3.77762418e-01 -1.85705619e-01  9.80243471e-01\n",
      "   4.09849499e-01  1.28714179e+00  1.15373511e-01  9.68872811e-01\n",
      "   6.72551419e-02 -3.12676056e-01 -6.90581554e-01  1.97368646e+00\n",
      "  -1.03298236e+00  2.62214219e+00  1.87016193e-01 -2.01384363e-02\n",
      "  -1.56002888e+00  1.57648100e+00  5.24921060e-02  2.64951619e-01]\n",
      " [-2.63269294e+00 -1.75444022e+00  8.70693624e-02  5.14374809e-01\n",
      "  -9.91413167e-01 -6.30455086e-01 -1.62147007e+00 -3.98872000e-01\n",
      "   2.07861186e-01 -1.58962008e+00  3.44919713e-01 -6.32535563e-01\n",
      "   6.97544853e-01 -4.92230774e-01  2.84972355e-01 -3.05345370e-01\n",
      "   1.92223837e+00 -6.76972613e-01  4.36939770e-01 -1.64348737e-01\n",
      "  -2.49647480e-01 -3.93802501e-01  5.80178908e-01  1.43740188e+00\n",
      "  -1.82094771e+00  5.80830950e-01 -3.57986768e-01  1.48951865e+00\n",
      "  -9.36153692e-01  3.47991091e-01 -3.67163352e-01  4.61684399e-01\n",
      "  -1.67181853e-01 -3.25425518e-02 -4.39441901e-01  1.31360686e+00\n",
      "  -6.30060351e-02  4.80344355e-01 -4.78094820e-01  9.68603910e-03\n",
      "  -1.55504902e+00  1.37190873e+00 -1.52179874e+00  1.10680490e+00\n",
      "   3.12166332e-02 -3.74924580e-01 -1.67511581e-01  9.75689009e-01\n",
      "   4.30161798e-01  1.28403964e+00  1.22800934e-01  9.67291919e-01\n",
      "   1.26123284e-01 -2.97114087e-01 -6.80930554e-01  1.96708841e+00\n",
      "  -1.00537525e+00  2.58887439e+00  2.20947268e-01 -4.82570681e-03\n",
      "  -1.51558539e+00  1.57370890e+00  6.31893395e-02  2.92471492e-01]]\n"
     ]
    }
   ],
   "source": [
    "Z1 = layer_norm(residual_1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bb40b",
   "metadata": {},
   "source": [
    "# 3. Feed Forward Network\n",
    "FFN(x)=max(0,xW1​+b1​)W2​+b2​\n",
    "\n",
    "apply FFN to each token independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3477b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64  # input layer\n",
    "d_ff = 256  # hidden layer\n",
    "\n",
    "W1 = np.random.randn(d_model, d_ff) / np.sqrt(d_model)\n",
    "b1 = np.zeros(d_ff)\n",
    "\n",
    "W2 = np.random.randn(d_ff, d_model) / np.sqrt(d_ff)\n",
    "b2 = np.zeros(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2875e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "900c7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x):\n",
    "    hidden = relu(np.matmul(x, W1) + b1)\n",
    "    output = np.matmul(hidden, W2) + b2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96a77421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 64)\n"
     ]
    }
   ],
   "source": [
    "ffn_output = feed_forward(Z1)\n",
    "print(ffn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb30890",
   "metadata": {},
   "source": [
    "# 4. Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9831e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_2 = Z1 + ffn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1ff92cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 64)\n"
     ]
    }
   ],
   "source": [
    "Z2 = layer_norm(residual_2)\n",
    "print(Z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ed74b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aef324c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get token indices\n",
    "idx_it = tokens.index(\"it\")\n",
    "idx_animal = tokens.index(\"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f4292a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head 0: it -> animal = 0.0985 (baseline = 0.0909)\n",
      "Head 1: it -> animal = 0.0983 (baseline = 0.0909)\n",
      "Head 2: it -> animal = 0.0629 (baseline = 0.0909)\n",
      "Head 3: it -> animal = 0.0866 (baseline = 0.0909)\n",
      "Head 4: it -> animal = 0.0673 (baseline = 0.0909)\n",
      "Head 5: it -> animal = 0.1049 (baseline = 0.0909)\n",
      "Head 6: it -> animal = 0.0902 (baseline = 0.0909)\n",
      "Head 7: it -> animal = 0.0745 (baseline = 0.0909)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check per-head attention\n",
    "\n",
    "baseline = 1 / len(tokens)\n",
    "\n",
    "for h in range(num_heads):\n",
    "    val = attention_weights[h, idx_it, idx_animal]\n",
    "    print(f\"Head {h}: it -> animal = {val:.4f} (baseline = {baseline:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90c27bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head 0 - top attention for 'it': \n",
      "       the: 0.1084\n",
      "    animal: 0.0985\n",
      "       the: 0.0957\n",
      "    street: 0.0954\n",
      "     cross: 0.0945\n",
      "\n",
      "Head 1 - top attention for 'it': \n",
      "       the: 0.1359\n",
      "     tired: 0.1144\n",
      "    animal: 0.0983\n",
      "       was: 0.0941\n",
      "    street: 0.0850\n",
      "\n",
      "Head 2 - top attention for 'it': \n",
      "       the: 0.1368\n",
      "     cross: 0.1223\n",
      "    street: 0.1161\n",
      "     tired: 0.1032\n",
      "       not: 0.0926\n",
      "\n",
      "Head 3 - top attention for 'it': \n",
      "    street: 0.0955\n",
      "   because: 0.0951\n",
      "       was: 0.0940\n",
      "     tired: 0.0939\n",
      "        it: 0.0935\n",
      "\n",
      "Head 4 - top attention for 'it': \n",
      "     tired: 0.1243\n",
      "       was: 0.1115\n",
      "        it: 0.1031\n",
      "   because: 0.1002\n",
      "    street: 0.0986\n",
      "\n",
      "Head 5 - top attention for 'it': \n",
      "       did: 0.1098\n",
      "       not: 0.1084\n",
      "    animal: 0.1049\n",
      "     tired: 0.0983\n",
      "     cross: 0.0971\n",
      "\n",
      "Head 6 - top attention for 'it': \n",
      "       the: 0.1040\n",
      "    street: 0.1020\n",
      "       the: 0.1010\n",
      "     cross: 0.0955\n",
      "   because: 0.0938\n",
      "\n",
      "Head 7 - top attention for 'it': \n",
      "       not: 0.1384\n",
      "     cross: 0.1296\n",
      "       did: 0.1081\n",
      "       the: 0.1014\n",
      "       was: 0.0830\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Top-k words attended by \"it\"\n",
    "\n",
    "for h in range(num_heads):\n",
    "    row = attention_weights[h, idx_it]\n",
    "    top = np.argsort(row)[::-1][:5]\n",
    "\n",
    "    print(f\"\\nHead {h} - top attention for 'it': \")\n",
    "    for i in top:\n",
    "        print(f\"{tokens[i]:>10s}: {row[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
