{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e0b0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2332e",
   "metadata": {},
   "source": [
    "# 1. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48aa9137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'animal',\n",
       " 'did',\n",
       " 'not',\n",
       " 'cross',\n",
       " 'the',\n",
       " 'street',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'tired',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data import  get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(\"The animal did not cross the street because it was tired.\")\n",
    "tokens  # simple tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d40b5925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1lines [00:00, 5584.96lines/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x000001E0A8FF1310>>, {'<unk>': 0, '<pad>': 1, 'the': 2, '.': 3, 'animal': 4, 'because': 5, 'cross': 6, 'did': 7, 'it': 8, 'not': 9, 'street': 10, 'tired': 11, 'was': 12})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Build Vocab\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    [tokens],\n",
    ")\n",
    "\n",
    "print(vocab.stoi)  # dict/vocab created with ids, stoi (string to int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b23e5b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['the']  # access token id from vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5efeb46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "7\n",
      "9\n",
      "6\n",
      "2\n",
      "10\n",
      "5\n",
      "8\n",
      "12\n",
      "11\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(vocab[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbbd7f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids: tensor([ 2,  4,  7,  9,  6,  2, 10,  5,  8, 12, 11,  3])\n"
     ]
    }
   ],
   "source": [
    "# 2. torch Tensor  \n",
    "token_ids = [vocab[token] for token in tokens]  # loop for store only ids in list\n",
    "token_ids = torch.tensor(token_ids, dtype=torch.long)  # create torch tensor\n",
    "print(f\"token_ids: {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57a5fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Embedding\n",
    "vocab_size = len(vocab) # 12\n",
    "embedding_dim = 64\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "X = embedding(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b347ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ec138",
   "metadata": {},
   "source": [
    "# 2. Linear Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e871834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "d_k = d_v = 64\n",
    "\n",
    "W_q = torch.randn(d_model, d_k)\n",
    "W_k = torch.randn(d_model, d_k)\n",
    "W_v = torch.randn(d_model, d_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9a9f3",
   "metadata": {},
   "source": [
    "# 3. Compute attention Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1f6dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.matmul(X, W_q)\n",
    "K = torch.matmul(X, W_k)\n",
    "V = torch.matmul(X, W_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0207971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6119890",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.matmul(Q, K.T)  # Q -> ([12, 64]),  K.T -> ([64, 12]), score -> ([12, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a8b7603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e397135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9968\\3243516198.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d_k = torch.tensor(d_k, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "d_k = torch.tensor(d_k, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7197c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = score / torch.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1be4c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)  # attention is applied across keys dimension.\n",
    "attn_weight = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6123e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.matmul(attn_weight, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7c06442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
